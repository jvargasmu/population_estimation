Sender: LSF System <lsfadmin@eu-g3-004>
Subject: Job 196695624: <popest> in cluster <euler> Exited

Job <popest> was submitted from host <eu-login-37> by user <metzgern> in cluster <euler> at Tue Dec 14 08:40:47 2021
Job was executed on host(s) <8*eu-g3-004>, in queue <gpu.24h>, as user <metzgern> in cluster <euler> at Tue Dec 14 08:41:20 2021
</cluster/home/metzgern> was used as the home directory.
</cluster/work/igp_psr/metzgern/HAC/code/repocode/population_estimation> was used as the working directory.
Started at Tue Dec 14 08:41:20 2021
Terminated at Tue Dec 14 08:49:46 2021
Results reported at Tue Dec 14 08:49:46 2021

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/bash

#BSUB -W 24:00
#BSUB -n 8
#BSUB -R "rusage[mem=14000,ngpus_excl_p=1]"
#BSUB -R "select[gpu_mtotal0>=6000]"
##BSUB -R "rusage[scratch=12500]"
#BSUB -J "popest"

# job index (set this to your system job variable e.g. for parallel job arrays)
# used to set model_idx and test_fold_idx below.
#index=0   # index=0 --> model_idx=0, test_fold_idx=0
index=$((LSB_JOBINDEX - 1))
val_fold=$(( $index % 5 ))

leave=Clipart

# cp -r /scratch2/Code/stylebias/data/OfficeHome $TMPDIR/
# cp -r /cluster/work/igp_psr/nkalischek/stylebias/data/OfficeHome $TMPDIR/
# cp -r /cluster/work/igp_psr/metzgern/HAC/code/codeJohn main/population_estimation/datasets $TMPDIR/

echo job index: $index
echo leave: $leave
echo val_fold: $val_fold

source HACenv/bin/activate

# load modules
module load gcc/8.2.0 gdal/3.2.0 zlib/1.2.9 eth_proxy hdf5/1.10.1


python superpixel_disagg_model.py   -train moz \
                                    -train_lvl f \
                                    -test moz \
                                    -lr 0.0001 \
                                    -optim adam \
                                    -wr 0.001 \
                                    -adamwr 0. \
                                    -lstep 8000 \
				    -mm m \
                                    --validation_fold ${val_fold} \
                                    --loss laplaceNLL \
                                    --input_scaling True \
                                    --output_scaling True

# python3 train.py --optimizer ADAM \
#                  --scheduler MultiStepLR \
#                  --base_learning_rate 0.00001 \
#                  --max_epochs 400 \
#                  --num_outputs 65 \

(... more ...)
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   319.06 sec.
    Max Memory :                                 35414 MB
    Average Memory :                             21889.16 MB
    Total Requested Memory :                     112000.00 MB
    Delta Memory :                               76586.00 MB
    Max Swap :                                   180 MB
    Max Processes :                              7
    Max Threads :                                33
    Run time :                                   506 sec.
    Turnaround time :                            539 sec.

The output (if any) follows:

job index: -1
leave: Clipart
val_fold: -1
/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/torch/distributed/distributed_c10d.py:153: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
wandb: Currently logged in as: mp20 (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.12.2
wandb: Syncing run pretty-leaf-1114
wandb:  View project at https://wandb.ai/nandometzger/HAC
wandb:  View run at https://wandb.ai/nandometzger/HAC/runs/1oal7scu
wandb: Run data is saved locally in /cluster/work/igp_psr/metzgern/HAC/code/repocode/population_estimation/wandb/run-20211214_084143-1oal7scu
wandb: Run `wandb offline` to turn off syncing.

/cluster/work/igp_psr/metzgern/HAC/data/OtherBuildings/MOZ/moz_wpop_regions.tif
read /cluster/work/igp_psr/metzgern/HAC/data/OtherBuildings/MOZ/MOZ_gbp_BCB_v1_count.tif
read /cluster/work/igp_psr/metzgern/HAC/data/OtherBuildings/MOZ/MOZ_mbp_BCB_v3_count.tif
read /cluster/work/igp_psr/metzgern/HAC/data/OtherBuildings/MOZ/MOZ_gbp_BCB_v1_mean_area.tif
read /cluster/work/igp_psr/metzgern/HAC/data/OtherBuildings/MOZ/MOZ_mbp_BCB_v3_mean_area.tif
read /cluster/work/igp_psr/metzgern/HAC/data/Covariates/MOZ/Accessibility/moz_tt50k_100m_2000.tif
read /cluster/work/igp_psr/metzgern/HAC/data/Covariates/MOZ/BSGM/2015/DTE/moz_dst_bsgme_100m_2015.tif
read /cluster/work/igp_psr/metzgern/HAC/data/Covariates/MOZ/BuiltSettlement/2014/DTE/moz_dst_ghslesaccilcgufghsll_100m_2014.tif
read /cluster/work/igp_psr/metzgern/HAC/data/Covariates/MOZ/Coastline/DST/moz_dst_coastline_100m_2000_2020.tif
read /cluster/work/igp_psr/metzgern/HAC/data/Covariates/MOZ/DMSP/moz_dmsp_100m_2011.tif
read /cluster/work/igp_psr/metzgern/HAC/data/Covariates/MOZ/ESA_CCI_Water/DST/moz_esaccilc_dst_water_100m_2000_2012.tif
read /cluster/work/igp_psr/metzgern/HAC/data/Covariates/MOZ/OSM/DST/moz_osm_dst_roadintersec_100m_2016.tif
read /cluster/work/igp_psr/metzgern/HAC/data/Covariates/MOZ/OSM/DST/moz_osm_dst_waterway_100m_2016.tif
read /cluster/work/igp_psr/metzgern/HAC/data/Covariates/MOZ/OSM/DST/moz_osm_dst_road_100m_2016.tif
read /cluster/work/igp_psr/metzgern/HAC/data/Covariates/MOZ/Slope/moz_srtm_slope_100m.tif
read /cluster/work/igp_psr/metzgern/HAC/data/Covariates/MOZ/Topo/moz_srtm_topo_100m.tif
read /cluster/work/igp_psr/metzgern/HAC/data/Covariates/MOZ/VIIRS/moz_viirs_100m_2015.tif
read /cluster/work/igp_psr/metzgern/HAC/data/Covariates/MOZ/WDPA/WDPA_1/moz_wdpa_dst_cat1_100m_2015.tif
  0% 0/413 [00:00<?, ?it/s]  2% 7/413 [00:00<00:06, 67.50it/s]  7% 30/413 [00:00<00:02, 158.21it/s] 12% 51/413 [00:00<00:02, 180.99it/s] 18% 73/413 [00:00<00:01, 196.07it/s] 23% 96/413 [00:00<00:01, 206.72it/s] 29% 119/413 [00:00<00:01, 214.06it/s] 34% 142/413 [00:00<00:01, 217.63it/s] 40% 165/413 [00:00<00:01, 221.26it/s] 46% 188/413 [00:00<00:01, 205.98it/s] 51% 210/413 [00:01<00:00, 209.88it/s] 56% 233/413 [00:01<00:00, 214.61it/s] 62% 256/413 [00:01<00:00, 218.06it/s] 68% 279/413 [00:01<00:00, 219.98it/s] 73% 302/413 [00:01<00:00, 221.87it/s] 79% 325/413 [00:01<00:00, 222.91it/s] 84% 348/413 [00:01<00:00, 220.76it/s] 90% 371/413 [00:01<00:00, 222.05it/s] 95% 394/413 [00:01<00:00, 222.51it/s]100% 413/413 [00:01<00:00, 212.34it/s]
0it [00:00, ?it/s]1it [00:13, 13.64s/it]2it [00:20,  9.86s/it]3it [00:28,  8.75s/it]4it [00:36,  8.40s/it]5it [00:43,  7.96s/it]6it [00:51,  7.92s/it]7it [00:59,  8.08s/it]8it [01:09,  8.65s/it]9it [01:17,  8.56s/it]10it [01:30,  9.92s/it]11it [01:39,  9.57s/it]12it [01:48,  9.34s/it]13it [01:56,  8.93s/it]14it [02:34, 17.80s/it]15it [03:46, 34.14s/it]15it [03:46, 15.11s/it]
  0% 0/156 [00:00<?, ?it/s]  9% 14/156 [00:00<00:01, 136.47it/s] 18% 28/156 [00:00<00:01, 121.07it/s] 31% 48/156 [00:00<00:00, 151.22it/s] 41% 64/156 [00:00<00:00, 150.86it/s] 54% 84/156 [00:00<00:00, 165.24it/s] 66% 103/156 [00:00<00:00, 172.96it/s] 78% 122/156 [00:00<00:00, 177.32it/s] 90% 140/156 [00:00<00:00, 177.55it/s]100% 156/156 [00:00<00:00, 166.45it/s]
0it [00:00, ?it/s]Preparing dataloader for:  ['moz']
1it [00:18, 18.48s/it]1it [00:18, 18.48s/it]
2021-12-14 08:49:34 INFO     Using no weighted sampler
Preparing moz
Initial: 3896.672256 mb used
After loading of variables 9130.192896 mb used
after loading of features 24465.75616 mb used
final usage 24466.116608 mb used
Dataloader ready.
using elementwise input scaling
using elementwise output scaling
  0% 0/100 [00:00<?, ?it/s]
  0% 0/54615 [00:00<?, ?it/s][A  0% 0/54615 [00:00<?, ?it/s]
  0% 0/100 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "superpixel_disagg_model.py", line 530, in <module>
    main()
  File "superpixel_disagg_model.py", line 504, in main
    superpixel_with_pix_data(
  File "superpixel_disagg_model.py", line 373, in superpixel_with_pix_data
    res, log_dict = PixAdminTransform(
  File "/cluster/work/igp_psr/metzgern/HAC/code/repocode/population_estimation/pix_transform/pix_admin_transform.py", line 458, in PixAdminTransform
    for sample in tqdm(train_loader):
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/tqdm/std.py", line 1180, in __iter__
    for obj in iterable:
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/torch/utils/data/dataloader.py", line 521, in __next__
    data = self._next_data()
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/torch/utils/data/dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/cluster/work/igp_psr/metzgern/HAC/code/repocode/population_estimation/utils.py", line 520, in __getitem__
    sample.append(self.get_single_training_item(i))
  File "/cluster/work/igp_psr/metzgern/HAC/code/repocode/population_estimation/utils.py", line 497, in get_single_training_item
    X = torch.tensor(self.features[name][0,:,rmin:rmax, cmin:cmax])
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "/cluster/apps/nss/gcc-8.2.0/python/3.8.5/x86_64/lib64/python3.8/site-packages/h5py/_hl/dataset.py", line 787, in __getitem__
    self.id.read(mspace, fspace, arr, mtype, dxpl=self._dxpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5d.pyx", line 192, in h5py.h5d.DatasetID.read
  File "h5py/_proxy.pyx", line 112, in h5py._proxy.dset_rw
OSError: Can't read data (wrong B-tree signature)
wandb: Waiting for W&B process to finish, PID 104591
wandb: Program failed with code 1.  Press ctrl-c to abort syncing.
wandb: - 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: / 0.00MB of 0.00MB uploaded (0.00MB deduped)wandb: - 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.00MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: | 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: / 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: - 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb: \ 0.01MB of 0.01MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: /cluster/work/igp_psr/metzgern/HAC/code/repocode/population_estimation/wandb/run-20211214_084143-1oal7scu/logs/debug.log
wandb: Find internal logs for this run at: /cluster/work/igp_psr/metzgern/HAC/code/repocode/population_estimation/wandb/run-20211214_084143-1oal7scu/logs/debug-internal.log
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced pretty-leaf-1114: https://wandb.ai/nandometzger/HAC/runs/1oal7scu

